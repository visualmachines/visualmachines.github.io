<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html class="fa-events-icons-ready" lang="en-US"><!--<![endif]--><head>

	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">	
	<!--[if lt IE 9]>
		<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<title>  CCD 2020 | CVPR workshop</title>
	<link rel="profile" href="http://gmpg.org/xfn/11">
	<!-- Favicons
	================================================== -->
	<link link="" rel="shortcut icon" href="index_files/favicon.png">
	
<!-- wp head -->
<link rel="dns-prefetch" href="http://s.w.org/">
<script src="index_files/6fd6937d87.js"></script><link href="index_files/6fd6937d87.css" media="all" rel="stylesheet">
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/svg\/","svgExt":".svg"};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55358,56794,8205,9794,65039],[55358,56794,8203,9794,65039]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script><script src="index_files/wp-emoji-release.js" type="text/javascript" defer="defer"></script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link rel="stylesheet" id="bootstrap-css" href="index_files/bootstrap.css" type="text/css" media="all">
<link rel="stylesheet" id="fancybox-css" href="index_files/jquery.css" type="text/css" media="all">
<link rel="stylesheet" id="flexslider-css" href="index_files/flexslider.css" type="text/css" media="all">
<link rel="stylesheet" id="style-css" href="index_files/style.css" type="text/css" media="all">
<link rel="stylesheet" id="skin-css" href="index_files/default.css" type="text/css" media="all">
<script type="text/javascript" src="index_files/jquery.js"></script>
<script type="text/javascript" src="index_files/jquery-migrate.js"></script>
<meta name="generator" content="WordPress 4.9.2">
		<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>
		<link id="template-colors" href="index_files/yellow.html" rel="stylesheet">
</head>
<body class="page-template-default page page-id-1145 body">
		
<div id="wrapper">
<!-- PAGE TITLE -->
<header>
<div class="navbar navbar-default navbar-static-top">
<div class="container">
<div class="navbar-header"><a class="navbar-brand" href="http://ccd2020.cms.caltech.edu/">CCD 2020</a><br>
<!-- June 14,15, or 19</div> -->
<div class="navbar-collapse collapse ">
<ul class="nav navbar-nav">
<li class="active"><a href="http://ccd2020.cms.caltech.edu/">Home</a></li>
<li><a href="#schedule">Schedule</a></li>
<li><a href="#keynotes">Keynotes</a></li>
<li><a href="#spotlights">Accepted Spotlights</a></li>
<li><a href="#people">People</a></li>
	<li><a href="#participate">Participate</a></li>

</ul>
</div>
</div>
</div>
</header>
<section id="featured">
<div id="main-slider" class="flexslider">
<ul class="slides">
<li style="width: 100%; height: 100%; float: left; margin:0 auto; position: relative; display: list-item;" class="flex-active-slide"><img src="Lens_LargerCrop.png" alt="">
<div class="flex-caption">
<h3>CCD 2020</h3>
<p>CVPR workshop on cutting edge research on cameras and displays</p>
</div>
</li>
</ul>
</div>
</li>

<!--<li style="width: 100%; float: left; margin-right: -100%; position: relative; display: none;" class=""><img src="index_files/banner1.jpg" alt="">-->
<!--<div class="flex-caption">-->
<!--<h3>Talks</h3>-->
<!--<p>The CCD program is now available!</p>-->
<!--<p><a class="btn btn-theme" href="#program">Learn More</a></p>-->
<!--</div>-->
<!--</li>-->
</ul>
<!--
<ul class="flex-direction-nav">
<li><a class="flex-prev" href="#">Previous</a></li>
<li><a class="flex-next" href="#">Next</a></li>
</ul>
<ol class="flex-control-nav flex-control-paging"><li><a class="flex-active">1</a></li><li><a class="">2</a></li></ol><ul class="flex-direction-nav"><li><a class="flex-prev" href="#">Previous</a></li><li><a class="flex-next" href="#">Next</a></li></ul></div>
-->
</section>
<section class="callaction">
<div class="container">
<div class="row">
<div class="col-lg-12">
<div class="big-cta">
<h2>Computational Cameras and Displays</h2>
<div align="justify">
<p><strong>Computational photography</strong> has become an increasingly active 
area of research within the computer vision community. Within the few 
last years, the amount of research has grown tremendously with dozens of
 published papers per year in a variety of vision, optics, and graphics 
venues. A similar trend can be seen in the emerging field of 
computational displays – spurred by the widespread availability of 
precise optical and material fabrication technologies, the research 
community has begun to investigate the joint design of display optics 
and computational processing. Such displays are not only designed for 
human observers but also for computer vision applications, providing 
high-dimensional structured illumination that varies in space, time, 
angle, and the color spectrum. This workshop is designed to unite the 
computational camera and display communities in that it considers to 
what degree concepts from computational cameras can inform the design of
 emerging computational displays and vice versa, both focused on 
applications in computer vision.</p>
<p>The CCD workshop series serves as an annual gathering place for 
researchers and practitioners who design, build, and use computational 
cameras, displays, and projector-camera systems for a wide variety of 
uses. The workshop solicits papers, posters, and demo submissions on all
 topics relating to projector-camera systems.</p>
<p><strong>Previous CCD Workshops:</strong><br>
<a href="http://focus.ece.ufl.edu/ccd2019/">CCD2019</a>, <a href="http://wisionlab.cs.wisc.edu/ccd2018">CCD2018</a>, <a href="http://www.computationalimaging.org/ccd2017/">CCD2017</a>, <a href="http://imagesci.ece.cmu.edu/CCD2016/">CCD2016</a>, <a href="http://ollie-imac.cs.northwestern.edu/~ollie/CCD2015/">CCD2015</a>, <a href="http://www.ece.rice.edu/~vb10/CVPR2014/CCD2014/index.php">CCD2014</a>, <a href="http://computationalcamerasanddisplays.media.mit.edu/">CCD2013</a>, <a href="http://computationalcamerasanddisplays.media.mit.edu/2012/">CCD2012</a></p>
</div>
</div>
</div>
</div>
</div>

	</section>
<section id="content">
<div class="container">
<div class="row">
<div class="col-lg-12">

	<centering>
	<iframe width="1100" height="562" src="https://www.youtube.com/embed/oxnZNSqCivE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

		<br>
		Download the group photos <a href="CCD_group_photo.zip"> here </a>
	</centering>

	<br><br>
	<!--
<div class="box-gray">
<h4>Instructions & Registration </h4>
The workshop will be broadcast live over Zoom starting at <strong> 8:45 AM Pacific June 19</strong> with live presentations and Q&amp;A during the times listed in the program below. After registering for the workshop at <a href="https://stanford.zoom.us/meeting/register/tJAscu-vrDwiGNQmf9h6t60Yc53XSvdETdHF">this link</a> you will be able to join the Zoom meeting. Pre-recorded videos can be viewed and questions can be posted asynchronously on the CVPR internal website, but we highly encourage attendance during the live session.

	<br>
	<br>
<strong><span><a style="font-size: 30px; color: red" href="https://stanford.zoom.us/meeting/register/tJAscu-vrDwiGNQmf9h6t60Yc53XSvdETdHF">REGISTER FOR LIVE EVENT</a></span></strong>
</div>
</div>
</div>

-->


<div class="row">
<div id="people" class="col-lg-12">
<!-- <h3 class="heading">People</h3> -->
<div class="box-gray">
<div align="justify">
<h4 class="heading">Workshop chairs</h4>
<a href="http://users.cms.caltech.edu/~klbouman/">Katherine L. (Katie) Bouman</a>, <i>California Institute of Technology</i><br>
<a href="https://visual.ee.ucla.edu/">Achuta Kadambi</a>, <i>University of California - Los Angeles</i><br>
	<p><a href="https://www.davidlindell.com/">David Lindell</a>, <i>Stanford University</i><br>
</p>
<!--<p>&nbsp;</p>-->

</div>
</div>
</div>
</div>


<!--
<div class="row">
<div id="program" class="col-lg-12">
<h4 class="heading">Program</h4>
<div align="center">
<table border="1px" cellspacing="5px" cellpadding="5px" bgcolor="#00FF00">
<tbody>
<tr>
<td align="left" valign="top">13:30 &#8211; 13:45</td>
<td align="left" valign="top"><strong>Welcome and Opening Remarks</strong></td>
</tr>
<tr>
<td align="left" valign="top">13:45 &#8211; 14:15</td>
<td align="left" valign="top"><p><strong>Keynote talk</strong></p>
<a href="https://jonbarron.info/">Jon Barron</a>, Google Research</p>
<p><i>Title: How to Learn a Camera </i></p>
</td>
</tr>
<tr>
<td align="left" valign="top">14:15 &#8211; 14:45</td>
<td align="left" valign="top"><p><strong>Keynote talk</strong></p>
<a href="https://people.eecs.berkeley.edu/~gkuo/">Grace Kuo</a>, UC Berkeley</p>
<p><i>Title: DiffuserCam: Compact Lensless Cameras for 3D Imaging.</i></p>
</td>
</tr>
<tr>
<td align="left" valign="top">14:45 &#8211; 15:15</td>
<td align="left" valign="top"><strong>Poster spotlights.</strong></td>
</tr>
<tr>
<td align="left" valign="top">15:15 &#8211; 16:30</td>
<td align="left" valign="top"><strong>Coffee break, Posters and demos.</strong></td>
</tr>
<tr>
<td align="left" valign="top">16:30 &#8211; 17:00</td>
<td align="left" valign="top"><p><strong>Keynote Talk</strong></p>
<a href="http://www.cs.cmu.edu/~yaser/">Yaser Ajmal Sheikh</a>, Robotics Institute - Carnegie Mellon and Occulus Research </p>
<p><i>Title: Machine Perception of Social Behavior </i></p>
</td>
</tr>
<tr>
<td align="left" valign="top">17:00 &#8211; 17:30</td>
<td align="left" valign="top"><p><strong>Keynote Talk</strong></p>
<a href="http://www.pa.ucla.edu/directory/jianwei-john-miao">John Miao</a>, Coherent Imaging Group at UCLA </p>
<p><i>Title: Exploring the 3D Nano and Atomic World with Computational Microscopy. </i></p>
</td>
</tr>
<td align="left" valign="top">17:30 &#8211; 17:45</td>
<td align="left" valign="top"><p><strong>Keynote talk</strong></p>
<a href="http://csms.haifa.ac.il/profiles/tTreibitz/index.html">Tali Treibitz</a>, Marine Imaging Lab at Leon H. Charney</p>
<p><i>Title: Insights from the Deep: How Can we Improve Underwater Vision? </i></p>
</td>
</tr>
<tr>
<td align="left" valign="top">17:45 &#8211; 18:00</td>
<td align="left" valign="top"><strong>Closing Remarks</strong></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
->

<!-- Key Notes -->
<div class="row">
<div id="keynotes" class="col-lg-12">
<h3 class="heading">Keynote Talks</h3>
<div class="box-gray">

<section id="efros_talk">
<p><img class="alignnone size-full wp-image-1369" src="efros.jpg" alt="Efros" style="height: 250px; width: auto;"></p>
<h4><a href="https://people.eecs.berkeley.edu/~efros/">Alexei (Alyosha) Efros</a>, UC Berkeley</h4>
<p><strong>Title:</strong> Using Machine Learning to Detect Image Manipulation</p>

<!-- <p><strong>Title:</strong> DiffuserCam: Compact Lensless Cameras for 3D Imaging.</p>


<p><strong>Bio:</strong>  Grace Kuo a PhD student in the department of Electrical Engineering and Computer Science at UC Berkeley, advised by Professor Laura Waller and Professor Ren Ng. She graduated from Washington University in St. Louis in 2015 with a degree in Electrical Engineering.
Her research is in computational imaging, which is the joint design of hardware and algorithms for imaging systems. I work at the intersection of optics, signal processing, computer graphics, and optimization.</p>
</section>
-->


<br>
<section id="susstrunk_talk">
<p><img class="alignnone size-full wp-image-1369" src="susstrunk.jpg" alt="Susstrunk" style="height: 250px; width: auto;"></p>
<h4><a href="https://people.epfl.ch/sabine.susstrunk">Sabine Susstrunk</a>, EPFL</h4>
<p><strong>Title:</strong> Denoising re-visited...once again</p>

<!-- <p><strong>Title:</strong> How to Learn a Camera</p>


<p><strong>Bio:</strong>  Jon Barron a staff research scientist at Google Research, where he works on computer vision and computational photography. At Google he's worked on Lens Blur, HDR+, Jump, Portrait Mode, and Glass.
Jon did his PhD at UC Berkeley, where he was advised by Jitendra Malik and funded by the NSF GRFP. He has spent time at Google[x], MIT CSAIL, Captricity, NASA Ames, Google NYC, the NYU MRL, Novartis, and Astrometry.net. Jon finished his bachelors at the University of Toronto.</p>
</section> -->

	<br>
<section id="irani_talk">
<p><img class="alignnone size-full wp-image-1369" src="irani.jpg" alt="Irani" style="height: 250px; width: auto;"></p>
<h4><a href="http://www.weizmann.ac.il/math/irani/home">Michal Irani</a>, Weizmann Institute of Science</h4>
<p><strong>Title:</strong> Deep Internal Learning </p>

<!-- <p><strong>Title:</strong> How to Learn a Camera</p>


<p><strong>Bio:</strong>  Jon Barron a staff research scientist at Google Research, where he works on computer vision and computational photography. At Google he's worked on Lens Blur, HDR+, Jump, Portrait Mode, and Glass.
Jon did his PhD at UC Berkeley, where he was advised by Jitendra Malik and funded by the NSF GRFP. He has spent time at Google[x], MIT CSAIL, Captricity, NASA Ames, Google NYC, the NYU MRL, Novartis, and Astrometry.net. Jon finished his bachelors at the University of Toronto.</p>
</section> -->




<!-- <p><strong>Title:</strong> Exploring the 3D Nano and Atomic World with Computational Microscopy. </p>


<p><strong>Bio:</strong> Jianwei (John) Miao is Professor of Physics & Astronomy and California NanoSystems Institute
at UCLA. He received a Ph. D. in Physics, a M. S. in computer science, and an Advanced
Graduate Certificate in Biomedical Engineering from State University of New York at Stony
Brook in 1999. After graduation, he became a Staff Scientist at the SLAC National Accelerator
Laboratory, Stanford University. In 2004, he moved to UCLA as an Assistant Professor and was
promoted to Full Professor in 2009. Miao is an internationally renowned pioneer in the
development of novel imaging methods with X-rays and electrons, and has made contributions
to theory, computation, and experiment. He theoretically explained under what conditions the
phase problem of non-crystalline specimens can be solved in 1998. A year later, he performed
the seminal experiment on extending X-ray crystallography to allow structural determination of
non-crystalline specimens, which is known as coherent diffractive imaging (CDI), lensless or
computational microscopy. CDI methods including Bragg CDI and ptychography have been
broadly implemented using synchrotron radiation, X-ray free electron lasers (XFELs), high
harmonic generation, optical lasers, and electrons. It has also become one of the major
justifications for the construction of XFELs worldwide, each of which costs hundreds of millions
of dollars.</p>
</section> -->

<br>
	<section id="wetzstein_talk">
<p><img class="alignnone size-full wp-image-1369" src="wetzstein.jpg" alt="Gordon Wetzstein" style="height: 250px; width: auto;"></p>
<h4><a href="https://stanford.edu/~gordonwz/">Gordon Wetzstein</a>, Stanford</h4>
<p><strong>Title:</strong> Computational Imaging at Stanford </p>


			<br>
<section id="liba_talk">
<p><img class="alignnone size-full wp-image-1369" src="liba.jpg" alt="Orly Liba" style="height: 250px; width: auto;"></p>
<h4><a href="https://sites.google.com/site/orlylibaprofessional/">Orly Liba</a>, Google </h4>
<p><strong>Title:</strong> Computational Photography in Very Low Light </p>


<!-- <p><strong>Title:</strong> Insights from the Deep: How Can we Improve Underwater Vision?</p>


<p><strong>Bio:</strong> Tali is the head of the Marine Imaging Lab, in the Department for Marine Technologies, Charney School of Marine Sciences, University of Haifa.
Previously she was a post-doc, working with David Kriegman in the Computer Vision group, Computer Science and Engineering department in the University of California, San Diego
and with Jules Jaffe in the Jaffe laboratory for Underwater Imaging in the Scripps Institution of Oceanography.</p>
-->
	</section>

	<br>
<section id="kamilov_talk">
<p><img class="alignnone size-full wp-image-1369" src="kamilov.jpg" alt="Ulugbek Kamilov" style="height: 250px; width: auto;"></p>
<h4><a href="https://cigroup.wustl.edu/">Ulugbek Kamilov</a>, Washington University in St. Louis</h4>
<p><strong>Title:</strong> Regularization by Artifact Removal (RARE): Image Reconstruction using Deep Priors Learned without Groundtruth </p>


<!-- <p><strong>Title:</strong> Insights from the Deep: How Can we Improve Underwater Vision?</p>


<p><strong>Bio:</strong> Tali is the head of the Marine Imaging Lab, in the Department for Marine Technologies, Charney School of Marine Sciences, University of Haifa.
Previously she was a post-doc, working with David Kriegman in the Computer Vision group, Computer Science and Engineering department in the University of California, San Diego 
and with Jules Jaffe in the Jaffe laboratory for Underwater Imaging in the Scripps Institution of Oceanography.</p>
-->

</section>

<br>
		<section id="sheinin_talk">
<p><img class="alignnone size-full wp-image-1369" src="sheninin.webp" alt="Mark Sheinin" style="height: 250px; width: auto;"></p>
<h4><a href="https://www.marksheinin.com/">Mark Sheinin</a>, Carnegie Mellon University (CMU)  </h4>
<p><strong>Title:</strong> The Yin and Yang of Structured Light in Computer Vision </p>


<!-- <p><strong>Title:</strong> Insights from the Deep: How Can we Improve Underwater Vision?</p>


<p><strong>Bio:</strong> Tali is the head of the Marine Imaging Lab, in the Department for Marine Technologies, Charney School of Marine Sciences, University of Haifa.
Previously she was a post-doc, working with David Kriegman in the Computer Vision group, Computer Science and Engineering department in the University of California, San Diego
and with Jules Jaffe in the Jaffe laboratory for Underwater Imaging in the Scripps Institution of Oceanography.</p>
-->
	</section>

<br>
	<section id="ingle_talk">
<p><img class="alignnone size-full wp-image-1369" src="ingle.jpg" alt="Atul Ingle" style="height: 250px; width: auto;"></p>
<h4><a href="https://atulingle.com/">Atul Ingle</a>, University of Wisconsin-Madison </h4>
<p><strong>Title:</strong> Computational Imaging with Single Photon Cameras </p>


<!-- <p><strong>Title:</strong> Insights from the Deep: How Can we Improve Underwater Vision?</p>


<p><strong>Bio:</strong> Tali is the head of the Marine Imaging Lab, in the Department for Marine Technologies, Charney School of Marine Sciences, University of Haifa.
Previously she was a post-doc, working with David Kriegman in the Computer Vision group, Computer Science and Engineering department in the University of California, San Diego
and with Jules Jaffe in the Jaffe laboratory for Underwater Imaging in the Scripps Institution of Oceanography.</p>
-->
	</section>




<br>
			<section id="xin_talk">
<p><img class="alignnone size-full wp-image-1369" src="xin.jpg" alt="Shumian Xin" style="height: 250px; width: auto;"></p>
<h4><a href="https://sites.google.com/site/shumianxin1015/">Shumian Xin</a>, Carnegie Mellon University (CMU)  </h4>
<p><strong>Title:</strong> A Theory of Fermat Paths for Non-Line-of-Sight Shape Reconstruction </p>


<!-- <p><strong>Title:</strong> Insights from the Deep: How Can we Improve Underwater Vision?</p>


<p><strong>Bio:</strong> Tali is the head of the Marine Imaging Lab, in the Department for Marine Technologies, Charney School of Marine Sciences, University of Haifa.
Previously she was a post-doc, working with David Kriegman in the Computer Vision group, Computer Science and Engineering department in the University of California, San Diego
and with Jules Jaffe in the Jaffe laboratory for Underwater Imaging in the Scripps Institution of Oceanography.</p>
-->
	</section>


</div>
</div>
</div>


		<div id="schedule" class="col-lg-12">
<h3 class="heading">Schedule</h3>
	<table border="1" cellpadding="2" cellspacing="0">
<tr style="font-weight: bold; background-color: #aaa;">
<td></td><td></td>
</tr>
<tr style="background-color: #f0f0f0">
<td>Time </td><td>Speakers</td>
</tr>
<tr style="background-color: #ffffff">
<td>Introduction (8:45 - 9:00)</td><td>&nbsp;</td>
</tr>
<tr style="background-color: #f0f0f0">
<td>First Block (9:00 - 10:30)</td><td>Michal Irani: Deep Internal Learning</td>
</tr>
<tr style="background-color: #ffffff">
<td>&nbsp;</td><td>Mark Sheinin: The Yin and Yang of Structured Light in Computer Vision</td>
</tr>
<tr style="background-color: #f0f0f0">
<td>&nbsp;</td><td>Ulugbek Kamilov: Regularization by Artifact Removal (RARE): Image Reconstruction using Deep Priors Learned without Groundtruth</td>
</tr>
<tr style="background-color: #ffffff">
<td>Break (10:30 - 10:45)</td><td>&nbsp;</td>
</tr>
<tr style="background-color: #f0f0f0">
<td>Second Block (10:45 - 12:00)</td><td>Sabine Susstrunk: Denoising re-visited...once again</td>
</tr>
<tr style="background-color: #ffffff">
<td>&nbsp;</td><td>Spotlights</td>
</tr>
<tr style="background-color: #f0f0f0">
<td>Lunch (12:00)</td><td>&nbsp;</td>
</tr>
<tr style="background-color: #ffffff">
<td>Third Block (1:00 - 2:45)</td><td>Gordon Wetzstein: Computational Imaging at Stanford</td>
</tr>
<tr style="background-color: #f0f0f0">
<td>&nbsp;</td><td>Atul Ingle: Computational Imaging with Single Photon Cameras</td>
</tr>
<tr style="background-color: #ffffff">
<td>&nbsp;</td><td>Spotlights</td>
</tr>
<tr style="background-color: #f0f0f0">
<td>Break (2:45 - 3:00)</td><td>&nbsp;</td>
</tr>
<tr style="background-color: #ffffff">
<td>Fourth Block (3:00 - 4:30)</td><td>Orly Liba: Computational Photography in Very Low Light</td>
</tr>
<tr style="background-color: #f0f0f0">
<td>&nbsp;</td><td>Shumian Xin: A Theory of Fermat Paths for Non-Line-of-Sight Shape Reconstruction</td>
</tr>
<tr style="background-color: #ffffff">
<td>&nbsp;</td><td>Alyosha Efros: Using Machine Learning to Detect Image Manipulation</td>
</tr>
<tr style="background-color: #f0f0f0">
<td>Final Remarks (4:30 - 4:45)</td><td>&nbsp;</td>
</tr>
</table>

			<br>
		<div id="spotlights" class="col-lg-12">
<h3 class="heading">Spotlights</h3>
	<table border="1" cellpadding="2" cellspacing="0">
<tr style="font-weight: bold; background-color: #aaa;">
<td></td><td></td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Title</td>
<td>Authors</td>
</tr>
<tr style="background-color: #ffffff;">
<td>A Monte Carlo framework for rendering speckle statistics in scattering media</td>
<td>Chen Bar, Marina Alterman, Ioannis Gkioulekas, Anat Levin</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Compressive video with lensless cameras</td>
<td>Nick Antipa, Patrick Oare, Emrah Bostan, Ren Ng, Laura Waller</td>
</tr>
<tr style="background-color: #ffffff;">
<td>Cosense: Learning a probabilistic strategy for computational imaging sensor selection</td>
<td>He Sun, Adrian V. Dalca, Katherine L. Bouman</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>DehazeGlasses: Optical dehazing with an occlusion-capable see-through display</td>
<td>Yuichi Hiroi, Takumi Kaminokado, Atsushi Mori, Yuta Itoh</td>
</tr>
<tr style="background-color: #ffffff;">
<td>Flatnet: Towards photorealistic scene reconstruction from lensless measurements</td>
<td>Salman S. Khan, Varun Sundar, Vivek Boominathan, Ashok Veeraraghavan, Kaushik Mitra</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>HeartCam: Camera-based physiology monitoring in the wild</td>
<td>Ewa M. Nowara, Tim K. Marks, Hassan Mansour, Amruta Pai, Genki Nagamatsu, Hiroshi Kawasaki, Ashok Veeraraghavan</td>
</tr>
<tr style="background-color: #ffffff;">
<td>Interferometric transmission probing with coded mutual intensity</td>
<td>Alankar Kotwal, Anat Levin, Ioannis Gkioulekas</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Keyhole Imaging: Non-line-of-sight imaging and tracking of moving objects along a single optical path</td>
<td>Christopher A. Metzler, David B. Lindell, Gordon Wetzstein</td>
</tr>
<tr style="background-color: #ffffff;">
<td>Memory-efficient learning for large-scale computational imaging systems</td>
<td>Michael Kellman, Eric Markley, Kevin Zhang, Jon Tamir, Emrah Bostan, Michael Lustig, Laura Waller</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Modeling defocus disparity in dual pixel sensors</td>
<td>Abhijith Punnappurath, Abdullah Abuolaim, Mahmoud Afifi, Michael S. Brown</td>
</tr>
<tr style="background-color: #ffffff;">
<td>MonSter: Awakening the mono in stereo</td>
<td>Yotam Gil, Shay Elmalem, Harel Haim, Emanuel Marom, Raja Giryes</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Optical backpropagation training method and its applications</td>
<td>Tiankuang Zhou, Lu Fang, Tao Yan, Jiamin Wu, Yipeng Li, Jingtao Fan, Huaqiang Wu, Xing Lin, Qionghai Dai</td>
</tr>
<tr style="background-color: #ffffff;">
<td>Optical Deep Residual Learning</td>
<td>Hongkun Dou, Yue Deng, Tao Yan, Huaqiang Wu, Xing Lin, Qionghai Dai</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Patch scanning displays: spatiotemporal enhancement for displays</td>
<td>Kaan Aksit</td>
</tr>
<tr style="background-color: #ffffff;">
<td>Photosequencing of motion blur using short and long exposures</td>
<td>Vijay Rengarajan, Shuo Zhao, Ruiwen Zhen, John Glotzbach, Hamid Sheikh, Aswin C. Sankaranarayanan</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Sea-thru: A method for removing water from underwater images</td>
<td>Derya Akkayanak, Tali Treibitz</td>
</tr>
<tr style="background-color: #ffffff;">
<td>Spatiotemporal Coded Imaging for Motion Deblurring</td>
<td>Shay Elmalem, Raja Giryes, Emanuel Marom</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Spectral DiffuserCam: Lensless snapshot hyperspectral imaging with a spectral filter array</td>
<td>Kristina Monokhova, Kyrollos Yanny, Neerja Aggarwal, Laura Waller</td>
</tr>
<tr style="background-color: #ffffff;">
<td>SweepCam—depth-aware lensless imaging using programmable masks</td>
<td>Yi Hua, Shigeki Nakamura, M. Salman Asif, Aswin C. Sankaranarayanan</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Towards learning-based inverse subsurface scattering</td>
<td>Chengqian Che, Fujun Luan, Shuang Zhao, Kavita Bala, Ioannis Gkioulekas</td>
</tr>
<tr style="background-color: #ffffff;">
<td>Towards occlusion-aware multifocal displays</td>
<td>Jen-Hao Rick Chang, Anat Levin, B.V.K Vijaya Kumar, Aswin C. Sankaranarayanan</td>
</tr>
<tr style="background-color: #f0f0f0;">
<td>Towards reflectometery from interreflections</td>
<td>Kfir Shem-Tov, Sai Praveen Bangaru, Anat Levin, Ioannis Gkioulekas</td>
</tr>
<tr style="background-color: #ffffff;">
<td>Towards unaligned guided thermal super-resolution</td>
<td>Honey Gupta, Kaushik Mitra</td>
</tr>
</tbody>
</table>



				<div class="row">
<div id="sponsors" class="col-lg-12">
<h3 class="heading">Sponsors</h3>
<div class="box-gray">

	<p><img class="alignnone size-full wp-image-1369" src="Algolux-2015-trimmedleft.png" alt="Algolux" style="width:400px"> &nbsp&nbsp&nbsp  <img class="alignnone size-full wp-image-1369" src="GoogleLogo2.png" alt="Google" style="width:350px">   &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp <img class="alignnone size-full wp-image-1369" src="Adobe-218x300.png" alt="Adobe"  style="width:170px"></p>

</div>
</div>
</div>
</div>


		<div class="row">
<div id="participate" class="col-lg-12">
<h3 class="heading">Participate</h3>
<div class="box-gray">
<h4>Spotlight Submissions</h4>
<div align="justify">


<p> CCD spotlights will give an opportunity to showcase previously published or yet-to-be published work to a larger community at CVPR. Due to the likely virtual format of this year's CVPR conference, accepted abstract submissions will be presented as a spotlight presentation during the main workshop.
This year selected spotlights will be selected through abstract submissions.
<p><strong>*Note: Submitted abstracts do not appear in any proceedings.</strong></p>
<p><strong> Submissions should include 1-2 paragraphs (at most 1 page) describing the proposed poster/demo, relevant figures, as well as author names and affiliations. Please send submissions by email directly to: <a href="mailto:ccd.workshop.2020@gmail.com"> ccd.workshop.2020@gmail.com</a>.</strong></p>

</div>
</div>
</div>
</div>


		<div class="row">
<div class="col-lg-12">
<div class="box-gray">
<h4>Important Dates</h4>
<ul>
<li>Spotlight submission deadline: <strong>May 29, 2020</strong></li>
<li>Spotlight decision: <strong>June 5, 2020</strong></li>
<li>Workshop date: <strong>June 19th, 2020</strong></li>
</ul>
<p>&nbsp;</p>
<h4>Venue</h4>
<p>The CCD workshop is part of the CVPR 2020 workshops. Please see the <a href="http://cvpr2020.thecvf.com/"><strong>CVPR webpage</strong></a> for information.
	<!-- on venue, accommodations, and other details. Note that while CVPR20 will happen in June as scheduled, the odds of a purely virtual meeting are significant. Please take this into consideration and avoid booking non-refundable travel reservations at this time.-->
	</p>
<!--<p>The CCD workshop is taking place at <strong>Room 254 - C</strong> of the convention center.-->
</div>
</div>
</div>


<!--
<div class="row">
<div id="posters" class="col-lg-12">
<h4 class="heading">Accepted Posters</h4>
<div align="center">
<table border="1px" cellspacing="5px" cellpadding="5px" bgcolor="#00FF00">
<tbody>
<tr>
<td align="left" valign="top">Wave-Based Non-Line-of-Sight Imaging using Fast f-k Migration	</td>
<td align="left" valign="top">David B. Lindell</td>
</tr>
<tr>
<td align="left" valign="top">Acoustic Non-Line-of-Sight Imaging</td>
<td align="left" valign="top">David B. Lindell</td>
</tr>
<tr>
<td align="left" valign="top">Image and Depth Estimation with Mask-Based Lensless Cameras</td>
<td align="left" valign="top">Salman Asif</td>
</tr>
<tr>
<td align="left" valign="top">Extreme Flux Imaging with Photon Counting Detectors</td>
<td align="left" valign="top">Atul Ingle</td>
</tr>
<tr>
<td align="left" valign="top">Efficient Scatter and Beam-Hardening Correction Cone-Beam CT	</td>
<td align="left" valign="top">Thilo Balke</td>
</tr>
<tr>
<td align="left" valign="top">Sual camera Bokeh smartphone demo	</td>
<td align="left" valign="top">David Liu</td>
</tr>
<tr>
<td align="left" valign="top">TW-SMNet: Multitask Deep Neural Networks for Tele-Wide Stereo Matching</td>
<td align="left" valign="top">Mostafa El-Khamy</td>
</tr>
<tr>
<td align="left" valign="top">Glitter Imaging for Single Image Camera Calibration	</td>
<td align="left" valign="top">Maya Shende</td>
</tr>
</tr>
<tr>
<td align="left" valign="top">PhaseCam3D - Learning Phase Masks for Passive Single View Depth Estimation	</td>
<td align="left" valign="top">Yicheng Wu</td>
</tr>
</tr>
<tr>
<td align="left" valign="top">WISH: Wavefront Imaging Sensor with High Resolution	</td>
<td align="left" valign="top">Yicheng Wu</td>
</tr>
</tr>
<tr>
<td align="left" valign="top">A Study on Sparsity Promoting Regularization Techniques with Full Constraints for Spectral Unmixing	</td>
<td align="left" valign="top">John Janiczek</td>
</tr>
<tr>
<td align="left" valign="top">Low Cost Edge Sensing for High Quality Demosaicking	</td>
<td align="left" valign="top">Yan Niu
</td>
</tr>
<tr>
<td align="left" valign="top">Subsampled Fourier Ptychography Using Generative Priors	</td>
<td align="left" valign="top">Fahad Shamshad</td>
</tr>
<tr>
<td align="left" valign="top">Phase Retrieval through Scattering Media via Generative Models	</td>
<td align="left" valign="top">Fahad Shamshad</td>
</tr>
<tr>
<td align="left" valign="top">Deep Photorealistic Reconstruction of Lensless Images	</td>
<td align="left" valign="top">Salman S. Khan</td>
</tr>
<tr>
<td align="left" valign="top">3D Imaging with Photon-Flooded Single-Photon Sensors	</td>
<td align="left" valign="top">Anant Gupta</td>
</tr>
<tr>
<td align="left" valign="top">Radiometric Compensation of Projector Displays by Modeling the Human Colour Response and Projector-Camera System Nonlinearity	</td>
<td align="left" valign="top">Matthew Post</td>
</tr>
<tr>
<td align="left" valign="top">Visual Deprojection	</td>
<td align="left" valign="top">Guha Balakrishnan</td>
</tr>
<tr>
<td align="left" valign="top">Low-Power Adaptive LIDAR with Deep Depth Completion	</td>
<td align="left" valign="top">Francesco Pittaluga</td>
</tr>

-->



</tbody>
</table>
</div>
</div>
</div>





<!-- People -->


<!--
<div class="row">
<div id="sponsors" class="col-lg-12">
<div align="justify">
<h3 class="heading">Sponsors</h3>
<div class="box-gray">
<p><strong>We are grateful to the following sponsors.</strong></p>

<p><a href="https://algolux.com/"><img src="algolux.png" alt="algolux logo" width="369"/></a></p>
<p>&nbsp;</p>
<p><a href="https://www.zillowgroup.com//"><img src="Zillow-Group.png" alt="Zillow Logo" width="369"/></a></p>
<p>&nbsp;</p>
<p><a href="https://www.adobe.com//"><img src="Adobe.png" alt="Adobe Logo" width="128"/></a></p>
<p>&nbsp;</p>
-->

</div>
</div>
</div>
</div>


</div> <!--Container-->













						<div class="col-lg-4">   
	<aside class="right-sidebar">
    	
	</aside>
</div>
</section>
	<!-- FOOTER -->
<footer>
	<div class="container">
		<div class="row">
			<div class="col-lg-3 col-md-3 col-sm-6"></div>
			<div class="col-lg-3 col-md-3 col-sm-6"></div>
			<div class="col-lg-3 col-md-3 col-sm-6"></div>
			<div class="col-lg-3 col-md-3 col-sm-6"></div>
		</div>
	</div>
	<div id="sub-footer">
		<div class="container">
			<div class="row">
				<div class="col-lg-6">
					<div class="copyright">
						<p><strong>
							<span></span>
                            <!-- 
                                All the links in the footer should remain intact. 
                                You can delete the links only if you purchased the pro version.
                                Licensing information: https://bootstrapmade.com/license/
                                Purchase the pro version form: https://bootstrapmade.com/buy/?theme=ModernaWp
                            -->
                            | <a href="https://bootstrapmade.com/free-business-bootstrap-themes-website-templates/">Business Bootstrap Themes</a> by <a href="https://bootstrapmade.com/">BootstrapMade</a>
						</strong></p>
					</div>
				</div>
				<div class="col-lg-6"></div>
			</div>
		</div>
	</div>
</footer>
</div>
<a href="#" class="scrollup" style="display: block;"><i class="fa fa-angle-up active"></i></a>
	
<script type="text/javascript" src="index_files/jquery_004.js"></script>
<script type="text/javascript" src="index_files/bootstrap.js"></script>
<script type="text/javascript" src="index_files/jquery_002.js"></script>
<script type="text/javascript" src="index_files/jquery_003.js"></script>
<script type="text/javascript" src="index_files/prettify.js"></script>
<script type="text/javascript" src="index_files/jquery_005.js"></script>
<script type="text/javascript" src="index_files/setting.js"></script>
<script type="text/javascript" src="index_files/jquery_006.js"></script>
<script type="text/javascript" src="index_files/animate.js"></script>
<script type="text/javascript" src="index_files/comment-reply.js"></script>
<script type="text/javascript" src="index_files/verify.js"></script>
<script type="text/javascript" src="index_files/custom.js"></script>
<script type="text/javascript" src="index_files/wp-embed.js"></script>
<script type="text/javascript">
jQuery(document).ready(function($){
});
</script>
</body></html>
